from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# âœ… ëª¨ë¸ ì´ë¦„
model_name = "bigcode/starcoder2-3b"

# âœ… 2. í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained(
    model_name,
    use_fast=True
)

# âœ… 3. ëª¨ë¸ ë¡œë“œ (4bit, device_map ìë™ í• ë‹¹, CPU ì˜¤í”„ë¡œë“œ ê°€ëŠ¥)
# ê¸°ì¡´ ì½”ë“œ ìœ ì§€í•˜ë©´ì„œ ì´ ë¶€ë¶„ë§Œ ì¶”ê°€í•˜ì„¸ìš”
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",
    torch_dtype=torch.float16,
    max_memory={"cpu": "12GiB"}  
)

# âœ… 4. í…ŒìŠ¤íŠ¸ìš© ì‘ë‹µ í•¨ìˆ˜ (í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì…ë ¥ â†’ í…ìŠ¤íŠ¸ ì¶œë ¥)
#temperature, top_p ì¶”ê°€
def generate_response(prompt: str):
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    with torch.no_grad():
        outputs = model.generate(**inputs, max_new_tokens=512, temperature=0.1, top_p=0.8)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# âœ… 5. í…ŒìŠ¤íŠ¸ìš© ì£¼ì„ ìƒì„± í•¨ìˆ˜ (ì½”ë“œ ì…ë ¥ â†’ ì£¼ì„ ë¶™ì€ ì½”ë“œ ì¶œë ¥)
def annotate_code_with_comments(code: str):
    prompt = f"ë‹¤ìŒì€ íŒŒì´ì¬ ì½”ë“œì…ë‹ˆë‹¤. ê° ì¤„ì— ì£¼ì„ì„ ë‹¬ì•„ì£¼ì„¸ìš”. ë°˜ë³µëœ ë‹µë³€ì€ ì¶œë ¥í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”.\n\n{code}"
    return generate_response(prompt)

# âœ… 6. í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ ìˆ˜ì • í•¨ìˆ˜ (ì½”ë“œ ì…ë ¥ â†’ ìˆ˜ì • ëœ ì½”ë“œ ì¶œë ¥)
def modify_code(code: str):
    prompt = f"ë‹¤ìŒì€ íŒŒì´ì¬ ì½”ë“œì…ë‹ˆë‹¤. ì½”ë“œì— ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ìˆ˜ì •í•´ì£¼ì„¸ìš”. ë°˜ë³µëœ ë‹µë³€ì€ ì¶œë ¥í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”.\n\n{code}"
    return generate_response(prompt)


# âœ… 7. ì‹¤í–‰ ì˜ˆì‹œ
#if ë¬¸ì— ì½”ë“œ ìƒì„±(ì˜ˆì‹œ:ë²„ë¸”ì •ë ¬ì½”ë“œ ë§Œë“¤ì–´ì¤˜)ê³¼ ì½”ë“œ ìˆ˜ì •, ì£¼ì„ ì¶”ê°€ì˜ ê²½ìš°ë¥¼ ë‚˜ëˆ ì„œ ì…ë ¥ë°›ë„ë¡ ë§Œë“¤ê³ 
#ìˆ˜ì •ê³¼ ì£¼ì„ì€ ì½”ë“œ ì…ë ¥ì´ë‹ˆ End Code ì…ë ¥ ì „ê¹Œì§€ ê³„ì† ì…ë ¥ë°›ë„ë¡ ë³€ê²½
if __name__ == "__main__":
    print("ğŸ§  StarCoder2-3B model loaded.")
    while True:
        print("\n'ìƒì„±', 'ìˆ˜ì •', 'ì£¼ì„', 'ì¢…ë£Œ' ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ì‹œì˜¤")
        prompt = input("ğŸ’¬ Prompt: ")
        if prompt.lower() in ["exit", "quit", "ì¢…ë£Œ"]:
            break

        elif prompt.lower() in ["ìƒì„±"]:
            print('\nâœï¸ ì›í•˜ëŠ” ì½”ë“œ í˜•íƒœë¥¼ ì ì–´ì£¼ì„¸ìš”.')
            code_type = input("")
            code_type = f"ë‹¤ìŒì€ ì›í•˜ëŠ” íŒŒì´ì¬ ì½”ë“œì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤. ì ì ˆí•œ íŒŒì´ì¬ ì½”ë“œë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”. ë°˜ë³µëœ ë‹µë³€ì€ ì¶œë ¥í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”.\n\n{code_type}"
            response = generate_response(code_type)

        elif prompt.lower() in ["ì£¼ì„"]:
            print('\nâœï¸ ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.')
            print("ì…ë ¥ì„ ë§ˆì¹˜ë ¤ë©´ 'End Code' ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            code_lines = []

            while True:
                line = input()
                if line.strip() == "End Code":
                    break
                code_lines.append(line)

            user_code = "\n".join(code_lines)
            response = annotate_code_with_comments(user_code)

        elif prompt.lower() in ["ìˆ˜ì •"]:
            print('\nâœï¸ ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.')
            print("ì…ë ¥ì„ ë§ˆì¹˜ë ¤ë©´ 'End Code' ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            code_lines = []

            while True:
                line = input()
                if line.strip() == "End Code":
                    break
                code_lines.append(line)

            user_code = "\n".join(code_lines)
            response = modify_code(user_code)

        else:
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤")
            response = "ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”"
        
        print("\nğŸ§  ë‹µë³€:\n", response)